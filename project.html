<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-10-18 wo 17:37 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Master Project</title>
<meta name="author" content="Jeroen van Riel" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="style.css" />

<script src="org-info-jeroen.js">
// @license magnet:?xt=urn:btih:1f739d935676111cfff4b4693e3816e664797050&amp;dn=gpl-3.0.txt GPL-v3-or-Later
// @license-end
</script>

<script>
// @license magnet:?xt=urn:btih:1f739d935676111cfff4b4693e3816e664797050&amp;dn=gpl-3.0.txt GPL-v3-or-Later
org_html_manager.set("TOC_DEPTH", "3");
org_html_manager.set("LINK_HOME", "");
org_html_manager.set("LINK_UP", "");
org_html_manager.set("LOCAL_TOC", "0");
org_html_manager.set("VIEW_BUTTONS", "0");
org_html_manager.set("MOUSE_HINT", "underline");
org_html_manager.set("FIXED_TOC", "0");
org_html_manager.set("TOC", "0");
org_html_manager.set("VIEW", "overview");
org_html_manager.setup();  // activate after the parameters are set
// @license-end
</script>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Master Project</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orgdc2902c">1. papers</a>
<ul>
<li><a href="#org5c5f64f">1.1. scheduling</a>
<ul>
<li><a href="#org97cafdb">1.1.1. Zhang: Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning</a></li>
<li><a href="#org71a43e7">1.1.2. Han &amp; Yang: Research on Adaptive Job Shop Scheduling Problems Based on Dueling Double DQN</a></li>
<li><a href="#org1257d2c">1.1.3. Tassel: A Reinforcement Learning Environment For Job-Shop Scheduling</a></li>
<li><a href="#org8636998">1.1.4. mips</a></li>
<li><a href="#org97486d4">1.1.5. TRIANA Bosman PhD thesis</a></li>
<li><a href="#org3f438d4">1.1.6. pinedo chapter 7 - job shops</a></li>
<li><a href="#org9fa6a73">1.1.7. pinedo chapter 15 - adv. general purpose procedures</a></li>
<li><a href="#orge672505">1.1.8. search terms</a></li>
<li><a href="#org7b69bc6">1.1.9. less relevant</a></li>
<li><a href="#org28912e6">1.1.10. Integer and Combinatorial Optimization</a></li>
</ul>
</li>
<li><a href="#orgffe8b52">1.2. cop with rl</a>
<ul>
<li><a href="#org03dbf12">1.2.1. Deep reinforcement learning for transportation network combinatorial optimization: A survey</a></li>
<li><a href="#orgdb627df">1.2.2. How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey</a></li>
<li><a href="#org532e462">1.2.3. Solving Mixed Integer Programs Using Neural Networks</a></li>
<li><a href="#org4b571ac">1.2.4. Reinforcement Learning for Integer Programming: Learning to Cut</a></li>
<li><a href="#org232fd6d">1.2.5. Learning self-play agents for combinatorial optimization problems</a></li>
</ul>
</li>
<li><a href="#orgf0e2481">1.3. reinforcement learning</a>
<ul>
<li><a href="#org44c5531">1.3.1. MARL book</a></li>
<li><a href="#org6c32f6e">1.3.2. reinforce</a></li>
<li><a href="#org3157417">1.3.3. Disentangling Epistemic and Aleatoric Uncertainty in Reinforcement Learning</a></li>
</ul>
</li>
<li><a href="#org71128f7">1.4. traffic</a>
<ul>
<li><a href="#orgb7b1936">1.4.1. Boon &amp; Timmerman platoon forming</a></li>
<li><a href="#org3f9a87c">1.4.2. Oblakova</a></li>
<li><a href="#orgef835e8">1.4.3. Noaeen survey</a></li>
<li><a href="#org723d5f4">1.4.4. Hua Wei</a></li>
</ul>
</li>
<li><a href="#org6e570de">1.5. context</a>
<ul>
<li><a href="#org4c4e4f3">1.5.1. topics</a></li>
<li><a href="#orga3cf5e3">1.5.2. links</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org46de410">2. questions</a>
<ul>
<li><a href="#org446abfe">2.1. cutting planes</a></li>
</ul>
</li>
<li><a href="#org4198e1a">3. work</a>
<ul>
<li><a href="#org117f4d2">3.1. mip formulation</a>
<ul>
<li><a href="#org50727f9">3.1.1. scaling up</a></li>
<li><a href="#org6643119">3.1.2. unit testing</a></li>
<li><a href="#org7040285">3.1.3. entrypoints processing time</a></li>
</ul>
</li>
<li><a href="#org22dd891">3.2. rl formulation</a>
<ul>
<li><a href="#orgfb3523a">3.2.1. rl formulation</a></li>
<li><a href="#org9336096">3.2.2. marl</a></li>
</ul>
</li>
<li><a href="#orge1d6660">3.3. network editor</a>
<ul>
<li><a href="#org079e004">3.3.1. vis-network</a></li>
<li><a href="#orgc83caed">3.3.2. DataSet</a></li>
<li><a href="#org4358fb1">3.3.3. react-graph-vis wrapper</a></li>
<li><a href="#orgcc08653">3.3.4. vis-network-react</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>


<div id="outline-container-orgdc2902c" class="outline-2">
<h2 id="orgdc2902c"><span class="section-number-2">1.</span> papers</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org5c5f64f" class="outline-3">
<h3 id="org5c5f64f"><span class="section-number-3">1.1.</span> scheduling</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-org97cafdb" class="outline-4">
<h4 id="org97cafdb"><span class="section-number-4">1.1.1.</span> Zhang: <a href="https://arxiv.org/abs/2010.12367">Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning</a></h4>
</div>
<div id="outline-container-org71a43e7" class="outline-4">
<h4 id="org71a43e7"><span class="section-number-4">1.1.2.</span> Han &amp; Yang: <a href="https://ieeexplore.ieee.org/document/9218934">Research on Adaptive Job Shop Scheduling Problems Based on Dueling Double DQN</a></h4>
</div>
<div id="outline-container-org1257d2c" class="outline-4">
<h4 id="org1257d2c"><span class="section-number-4">1.1.3.</span> Tassel: <a href="https://arxiv.org/abs/2104.03760">A Reinforcement Learning Environment For Job-Shop Scheduling</a></h4>
<div class="outline-text-4" id="text-1-1-3">
<ul class="org-ul">
<li>based on time steps</li>
<li>intricate &ldquo;noop&rdquo; action</li>
</ul>
</div>

<ol class="org-ol">
<li><a id="org590e311"></a><a href="https://github.com/prosysscience/RL-Job-Shop-Scheduling">code</a><br /></li>
<li><a id="orgd5b6cab"></a>search-space reduction<br />
<div class="outline-text-5" id="text-1-1-3-2">
<ul class="org-ul">
<li>Provide a binary vector indicating which actions are legal.</li>
<li>Use non-final prioritization, i.e. favor other job when deciding between
&ldquo;final job&rdquo; (only one operation left) and non-final job.</li>
<li>Handle the &ldquo;No-Op&rdquo; action with special attention.</li>
<li>Heuristically disallow no-op when a lot of jobs can be allocated.</li>
</ul>
</div>
</li>
<li><a id="org99d23ad"></a>reward<br />
<div class="outline-text-5" id="text-1-1-3-3">
<p>
Instead of makespan (dense reward), they formulate a dense reward function based
on the amount of idle time introduced by the current decision.
</p>
</div>
</li>
<li><a id="orgbe0fe28"></a>algorithm<br />
<div class="outline-text-5" id="text-1-1-3-4">
<p>
single agent, actor-critic Proximal Policy Optimization
</p>
</div>
</li>
<li><a id="org8792bec"></a>experiments<br />
<div class="outline-text-5" id="text-1-1-3-5">
<p>
They compare there results with Google OR-Tools <a href="https://developers.google.com/optimization/scheduling/job_shop">Jop Shop Problem</a>.
</p>
</div>
</li>
<li><a id="orgbb8cf88"></a>follow-up (order swapping): <a href="https://www.mdpi.com/2504-4990/5/2/25">rl for scheduling with order swapping</a><br />
<div class="outline-text-5" id="text-1-1-3-6">
<p>
16,17
tsp: 18,19,20
knapsack: 7,16
steiner tree: 6
</p>

<p>
21 (Zhang and Dietterich): show potential of rl for JSSP in 1995 (this is the paper referenced in Pinedo)
8: overview of rl for scheduling
23: policy gradient showing feasibility of DRL in JSSPs
24: multi-agent MDP
25, 2: dueling double DQN with <i>prioritized reply (?)</i>, using the <span class="underline">disjunctive graph</span>
26 (Tassel): to improve generalization capabilities, use DRL with compact state space repr. and dense reward
</p>
</div>
<ol class="org-ol">
<li><a id="org3169410"></a>journal ranking: <a href="https://www.scopus.com/sourceid/21101109601#tabs=1">https://www.scopus.com/sourceid/21101109601#tabs=1</a><br /></li>
<li><a id="org2adaa51"></a>scaliro: <a href="https://www.scaliro.de/fleetengine">https://www.scaliro.de/fleetengine</a><br /></li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-org8636998" class="outline-4">
<h4 id="org8636998"><span class="section-number-4">1.1.4.</span> mips</h4>
<div class="outline-text-4" id="text-1-1-4">
</div>
<ol class="org-ol">
<li><a id="org5370c05"></a>blocking and no-wait<br />
<ol class="org-ol">
<li><a id="orgc770dcf"></a><a href="https://www.sciencedirect.com/science/article/pii/S0377221701003381">paper</a><br /></li>
<li><a id="orgd6b6bc4"></a>blocking<br />
<div class="outline-text-6" id="text-1-1-4-1-2">
<p>
Occurs when machine cannot continue unless the jobs &ldquo;leaves&rdquo; the machine (i.e.,
the next operation of the job is started).
</p>
</div>
</li>
<li><a id="orgcbd717f"></a>no-wait<br />
<div class="outline-text-6" id="text-1-1-4-1-3">
<p>
Two consecutive operations of a job must be processed without interruption.
</p>
</div>
</li>
</ol>
</li>
<li><a id="orgb526d77"></a>Lamorgese, Mannino (2019): <span class="underline">path&amp;cycle</span> method (non-compact formulation for job-shop)<br />
<div class="outline-text-5" id="text-1-1-4-2">
<p>
<b>A non-compact formulation for job-shop scheduling problems in traffic management</b>
</p>

<p>
&ldquo;Summarizing, in ([17, 18]) we apply the so called Logic Benders’ reformulation (see
[11]) in order to decompose the original problem into a &rdquo;line problem&ldquo; (i.e. relative to
the railway line) and a number of station problems (i.e. associated with each station),
with the line problem being a big-M formulation (of a scheduling problem). In this
paper we only focus on the line problem defined in the above decomposition, and pro-
ceeding from the classic Benders’ reformulation we show how to get rid of the big-M
constraints.&rdquo;
</p>
</div>

<ol class="org-ol">
<li><a id="org73e257f"></a>[17] Lamorgese, Mannino (2015): real-time train dispatching<br />
<div class="outline-text-6" id="text-1-1-4-2-1">
<p>
An Exact Decomposition Approach for the Real-Time Train Dispatching Problem
</p>

<ul class="org-ul">
<li>big-M and time-indexed methods are common</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgda13328"></a>decomposition<br />
<div class="outline-text-7" id="text-1-1-4-2-1-1">
<ul class="org-ul">
<li>master/slave: Line Dispatching (LD) and Station Dispatching (SD)
Note, we do not have such a station dispatching problem, our problem is similar to the LD problem alone.</li>
<li>combinatorial Benders&rsquo; cuts</li>
</ul>
</div>
</li>
</ol>
</li>
<li><a id="org78edcc4"></a>[18] Lamorgese, Mannino (2016): extends the above paper<br />
<div class="outline-text-6" id="text-1-1-4-2-2">
<p>
Optimal Train Dispatching by Benders&rsquo;-like reformulation
</p>
</div>
<ol class="org-ol">
<li><a id="org0da4a0b"></a>similar to my idea of combining variables?<br />
<div class="outline-text-7" id="text-1-1-4-2-2-1">
<p>
I want to combine decision variables for vehicles for which we know/determined that they will be &ldquo;following each other&rdquo; (order does not change) on a particular part of their shared route.
</p>

<p>
Ahhh, maybe they associate a variable to a &ldquo;set of precedence constraints&rdquo;, like
a &ldquo;pattern&rdquo; in the cutting stock problem. This drastically reduces the set of
variables, but requires row generation technique.
</p>

<p>
<b>Actual new idea is introduced in Section 3.1.</b>
</p>

<p>
Instead of &ldquo;meet at c&rdquo; (\(y\) variables), they now use &ldquo;meet before c&rdquo; / &ldquo;meet after c&rdquo; binary variables&#x2026;?
</p>

<p>
&ldquo;Adding these new variables and constraints to the model allows us to neglect the y variables and drop the associated constraints (4) and (6).&rdquo;
</p>

<ul class="org-ul">
<li>lazily add constraints for conflicting pairs of opposite/follower trains</li>
</ul>
</div>
</li>
</ol>
</li>
</ol>
</li>
<li><a id="org88f8588"></a>Sartor, Mannino, Bach (2019): combinatorial learning in traffic<br />
<div class="outline-text-5" id="text-1-1-4-3">
<p>
<a href="https://link.springer.com/chapter/10.1007/978-3-030-37599-7_32">Combinatorial Learning in Traffic Management</a>
</p>
<ul class="org-ul">
<li>re-optimization for <i>path&amp;cycle</i></li>
<li>using <i>pool of constraints</i></li>
</ul>

<p>
(from the same authors as <a href="https://www.sintef.no/en/publications/publication/1613267/">A novel formulation for job-shop scheduling in traffic
management</a>, but could not find the PDF of that publication)
</p>
</div>
<ol class="org-ol">
<li><a id="org641351f"></a>[10] Mannino, Sartor (2018): path&amp;cycle for air traffic<br /></li>
<li><a id="org0ea5c8e"></a>1. introduction<br />
<div class="outline-text-6" id="text-1-1-4-3-2">
<ul class="org-ul">
<li>[11] formal unifying framework for re-optimization</li>

<li>most work is on heuristics</li>
<li>[<a href="https://optimization-online.org/2018/08/6784/">7</a>] vehicle routing (branch-and-price) with column generation, &ldquo;where columns generated at the previous iterations are <b>massaged</b> and adapted to subsequent iterations&rdquo;</li>

<li>what is <b>blocking, no-wait</b> job-shop scheduling</li>
<li>two contending MILP formulations: big-M and <b>time-indexed (?)</b></li>

<li>path&amp;cycle [<a href="https://pubsonline.informs.org/doi/abs/10.1287/opre.2018.1837?journalCode=opre">4</a>] (train scheduling) is based on strenghtening the Benders&rsquo; reformulation of a natural big-M formulation</li>
<li>path&amp;cycle [<a href="https://sintef.brage.unit.no/sintef-xmlui/bitstream/handle/11250/2564824/OASIcs-ATMOS-2018-14.pdf?sequence=2">10</a>] (flight scheduling) with big-M</li>
<li>In our formulation, the number of rows grows exponentially with the number of vehicles as well.</li>

<li>delayed row and column generation</li>
<li>[2] adding optimality cuts -&gt; iteratively approximating objective</li>
<li>key of re-optimization: use this approximation (by keeping constraints) in subsequent solving</li>

<li>constraint pool
<ul class="org-ul">
<li>remove (vehicle leaves)</li>
<li>adjust (slightly changed schedule)</li>
<li>keep (still feasible)</li>
</ul></li>

<li>path&amp;cycle <b>cuts are interpretable</b>:
&ldquo;If vehicle a meets vehicle b in resource s, then vehicle a will be delayed
(in respect to its original schedule) by at least x seconds.&rdquo;</li>
</ul>
</div>
</li>

<li><a id="orgc4b5e11"></a>2. natural formulation<br />
<div class="outline-text-6" id="text-1-1-4-3-3">
<ul class="org-ul">
<li>planes <i>meeting</i> in <i>sectors</i></li>
<li>prevent schedules with <i>hotspots</i></li>

<li>precedence constraints</li>
<li>hotspot constraints (3) (c.f. &ldquo;cover inequalities&rdquo; for knapsack problem)</li>
</ul>

<p>
I find their notation for the disjunction [meet in sector, f before g, g before f] attractive.
Note that our formulation is kind of the same, but without the option to meet.
</p>
</div>
</li>

<li><a id="orgd2bd0b2"></a>3. path&amp;cycle and re-optimization<br />
<div class="outline-text-6" id="text-1-1-4-3-4">
<ul class="org-ul">
<li>disjunctive graph</li>
</ul>
</div>
</li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-org97486d4" class="outline-4">
<h4 id="org97486d4"><span class="section-number-4">1.1.5.</span> TRIANA Bosman PhD thesis</h4>
<div class="outline-text-4" id="text-1-1-5">
<p>
contains some interesting pointers (approximiate DP, column generation)
</p>

<ul class="org-ul">
<li>encoding the partial states in planning (partial schedules), like assigning a
subset of the jobs (particularly related to my own ideas about how we could
formulate scheduling as a RL problem)</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org61dc785"></a>(approximate) dynamic programming (partial &ldquo;planning&rdquo; states)<br /></li>
<li><a id="org36b38a6"></a>column generation<br /></li>
</ol>
</div>
<div id="outline-container-org3f438d4" class="outline-4">
<h4 id="org3f438d4"><span class="section-number-4">1.1.6.</span> pinedo chapter 7 - job shops</h4>
</div>
<div id="outline-container-org9fa6a73" class="outline-4">
<h4 id="org9fa6a73"><span class="section-number-4">1.1.7.</span> pinedo chapter 15 - adv. general purpose procedures</h4>
<div class="outline-text-4" id="text-1-1-7">
</div>
<ol class="org-ol">
<li><a id="orgbbb1504"></a><a href="https://www.ijcai.org/Proceedings/95-2/Papers/013.pdf">A Reinforcement Learning Approach to Job-shop Scheduling</a> (referenced by Pinedo)<br /></li>
<li><a id="org78a2933"></a>15.1 beam search<br /></li>
<li><a id="org838bef9"></a>15.2 decomposition methods and rolling horizon procedures<br />
<ol class="org-ol">
<li><a id="org0d4a8c1"></a>machine-based<br /></li>
<li><a id="org2dd1ad9"></a>job-based<br /></li>
<li><a id="org04c4baf"></a>time-based<br /></li>
<li><a id="org64fe074"></a>hybrid<br /></li>
</ol>
</li>
<li><a id="org4109b82"></a>15.3 constraint programming<br /></li>
<li><a id="org4aa6f98"></a>15.4 market-based and agent-based procedures<br /></li>
<li><a id="orge78547b"></a>15.5 procedures for scheduling problems with multiple objectives<br /></li>
</ol>
</div>
<div id="outline-container-orge672505" class="outline-4">
<h4 id="orge672505"><span class="section-number-4">1.1.8.</span> search terms</h4>
<div class="outline-text-4" id="text-1-1-8">
</div>
<ol class="org-ol">
<li><a id="orga8df9f3"></a><span class="underline">platoon forming algorithms</span> (don&rsquo;t forget this one!)<br /></li>
<li><a id="orgf459e2e"></a>online job shop<br /></li>
<li><a id="org0abcef4"></a>flexible job shop scheduling (with parallel machines)<br />
<div class="outline-text-5" id="text-1-1-8-3">
<p>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S037722172300382X">The flexible job shop scheduling problem: A review</a>
</p>
</div>
</li>
<li><a id="org0c4f9fd"></a>paperswithcode.com<br />
<div class="outline-text-5" id="text-1-1-8-4">
<p>
<a href="https://paperswithcode.com/task/job-shop-scheduling">https://paperswithcode.com/task/job-shop-scheduling</a>
</p>
</div>
</li>
<li><a id="orgc7b80dd"></a>job shop with finite buffers<br /></li>
<li><a id="orgfc37ff1"></a><span class="todo TODO">TODO</span> Taillard - <a href="https://www.sciencedirect.com/science/article/abs/pii/037722179390182M?via%3Dihub">Benchmarks for basic scheduling problems</a><br />
<ol class="org-ol">
<li><a id="org3b59db4"></a>cited by many interesting works with reinforcement learning<br />
<div class="outline-text-6" id="text-1-1-8-6-1">
<p>
They are of course not all directly related, but contain some interesting
aspects to consider in my own project, like benchmarking.
</p>
</div>
<ol class="org-ol">
<li><a id="orga24f6dc"></a><a href="https://www.sciencedirect.com/science/article/pii/S2210650223001724">example</a><br /></li>
<li><a id="org5656288"></a><a href="https://www.sciencedirect.com/science/article/pii/S0377221722010050">this one</a><br /></li>
</ol>
</li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-org7b69bc6" class="outline-4">
<h4 id="org7b69bc6"><span class="section-number-4">1.1.9.</span> less relevant</h4>
<div class="outline-text-4" id="text-1-1-9">
</div>
<ol class="org-ol">
<li><a id="org0db7074"></a><a href="https://www.duo.uio.no/bitstream/handle/10852/98936/1/Kloster_2022_Scheduling_vehicles_AAM.pdf">Scheduling vehicles with spatial conflicts</a> (planes at airport)<br />
<div class="outline-text-5" id="text-1-1-9-1">
<p>
Introduces a general definition for &ldquo;conflict region&rdquo;, in a concurrent positions
space \(\{(x^a(t), x^b(t)) : t \in [0,H]\}\).
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org28912e6" class="outline-4">
<h4 id="org28912e6"><span class="section-number-4">1.1.10.</span> <a href="https://link.springer.com/referenceworkentry/10.1007/978-1-4419-1153-7_129">Integer and Combinatorial Optimization</a></h4>
</div>
</div>
<div id="outline-container-orgffe8b52" class="outline-3">
<h3 id="orgffe8b52"><span class="section-number-3">1.2.</span> cop with rl</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org03dbf12" class="outline-4">
<h4 id="org03dbf12"><span class="section-number-4">1.2.1.</span> <a href="https://www.sciencedirect.com/science/article/pii/S0950705121007887?via%3Dihub#b68">Deep reinforcement learning for transportation network combinatorial optimization: A survey</a></h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
Contains list of papers exploring the idea of AlphaGo series to combinatorial optimization.
</p>
</div>
</div>
<div id="outline-container-orgdb627df" class="outline-4">
<h4 id="orgdb627df"><span class="section-number-4">1.2.2.</span> <a href="https://ieeexplore.ieee.org/document/9310691">How to Build a Graph-Based Deep Learning Architecture in Traffic Domain: A Survey</a></h4>
</div>
<div id="outline-container-org532e462" class="outline-4">
<h4 id="org532e462"><span class="section-number-4">1.2.3.</span> <a href="https://arxiv.org/abs/2012.13349">Solving Mixed Integer Programs Using Neural Networks</a></h4>
</div>
<div id="outline-container-org4b571ac" class="outline-4">
<h4 id="org4b571ac"><span class="section-number-4">1.2.4.</span> <a href="https://arxiv.org/abs/1906.04859">Reinforcement Learning for Integer Programming: Learning to Cut</a></h4>
</div>
<div id="outline-container-org232fd6d" class="outline-4">
<h4 id="org232fd6d"><span class="section-number-4">1.2.5.</span> <a href="https://www.cambridge.org/core/journals/knowledge-engineering-review/article/learning-selfplay-agents-for-combinatorial-optimization-problems/94DCEA2DA13BC51250F30038ECFECA52">Learning self-play agents for combinatorial optimization problems</a></h4>
</div>
</div>
<div id="outline-container-orgf0e2481" class="outline-3">
<h3 id="orgf0e2481"><span class="section-number-3">1.3.</span> reinforcement learning</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-org44c5531" class="outline-4">
<h4 id="org44c5531"><span class="section-number-4">1.3.1.</span> <a href="https://www.marl-book.com">MARL book</a></h4>
<div class="outline-text-4" id="text-1-3-1">
</div>
<ol class="org-ol">
<li><a id="orge8ff547"></a>1. introduction<br />
<div class="outline-text-5" id="text-1-3-1-1">
<p>
Agents choose actions independently to form a joint action.
</p>

<p>
Challenges:
</p>
<ul class="org-ul">
<li>Non-stationarity caused by learning agents.</li>
<li>Multi-agent credit assignment: which agent was (most) responsible for successful actions?</li>
<li>Optimality of policies and equilibrium selection: What is optimality? Which equilibrium to converge to? How to coordinate convergence to a chosen equilibrium?</li>
<li>Scaling number of agents.</li>
</ul>
</div>
</li>
<li><a id="org1bf84f3"></a>2. reinforcement learning<br />
<div class="outline-text-5" id="text-1-3-1-2">
<p>
(nothing new compared to Sutton &amp; Barto)
</p>
</div>
</li>
<li><a id="orgb33cfca"></a>3. games: models of multi-agent interaction<br />
<div class="outline-text-5" id="text-1-3-1-3">
<p>
Each agent takes a separate action, which together form a <i>joint action</i>.
</p>

<p>
Hierarchy of game models:
</p>
<ul class="org-ul">
<li>Partially Observable Stochastic Game
<ul class="org-ul">
<li>Stochastics Game
<ul class="org-ul">
<li>Normal-Form Game</li>
<li>MPD</li>
</ul></li>
<li>Dec-POMPD</li>
<li>POMDP</li>
</ul></li>
</ul>

<p>
Normal-form games form the basic building blocks of all game models in this
chapter, similarly to how multi-armed bandits may be considered the building
blocks of MDPs.
</p>

<ul class="org-ul">
<li>zero-sum game</li>
<li>common-reward game</li>
<li>general-sum game</li>
</ul>
</div>
</li>
<li><a id="org821f4f5"></a>4. solution concepts for games<br /></li>
<li><a id="orga5e9408"></a>5. marl in games: first steps and challenges<br /></li>
<li><a id="org2f8af52"></a>6. marl: foundational algorithms<br /></li>
</ol>
</div>
<div id="outline-container-org6c32f6e" class="outline-4">
<h4 id="org6c32f6e"><span class="section-number-4">1.3.2.</span> reinforce</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
<a href="https://mattalanwright.github.io/articles/reinforce/">https://mattalanwright.github.io/articles/reinforce/</a>
</p>
</div>
</div>
<div id="outline-container-org3157417" class="outline-4">
<h4 id="org3157417"><span class="section-number-4">1.3.3.</span> <a href="https://arxiv.org/abs/2206.01558">Disentangling Epistemic and Aleatoric Uncertainty in Reinforcement Learning</a></h4>
</div>
</div>
<div id="outline-container-org71128f7" class="outline-3">
<h3 id="org71128f7"><span class="section-number-3">1.4.</span> traffic</h3>
<div class="outline-text-3" id="text-1-4">
</div>
<div id="outline-container-orgb7b1936" class="outline-4">
<h4 id="orgb7b1936"><span class="section-number-4">1.4.1.</span> Boon &amp; Timmerman platoon forming</h4>
<div class="outline-text-4" id="text-1-4-1">
<p>
(??, ????)
</p>
<ul class="org-ul">
<li>scheduling part (which Marko told me was &ldquo;quite straightforward&rdquo;)</li>
<li>speed profile algorithm (minimzing queue lenght vs. energy consumption)</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgf240641"></a>2. Model formulation<br />
<div class="outline-text-5" id="text-1-4-1-1">
<p>
The PFA control area is larger than SPA control area, because the trajectory
needs to be fixed before vehicles enter the SPA area. In the PFA control area,
crossing times of vehicles may still be rescheduled upon new arrivals.
</p>
</div>
<ol class="org-ol">
<li><a id="org41529a6"></a>2.1 Platoon forming algorithms<br />
<div class="outline-text-6" id="text-1-4-1-1-1">
<p>
The platoon forming is based on an exhaustive and gated discipline. Exhaustive
just allows vehicles to join the current platoon as long as they are able to
catch up with it. The gated discipline &ldquo;fixes&rdquo; platoons once their lane is
visited by the server. In other words: &ldquo;Joining a platoon is only allowed if the
lane is not the lane from which vehicles are currently departing (the platoon is
not yet fixed).&rdquo;
</p>

<p>
Benefit of gated discipline is less variation in platoon sizes and, hence, less
variable cycle lenghts. This can be important when considering PFAs in a network
setting.
</p>
</div>
</li>
</ol>
</li>
<li><a id="orgbf32337"></a>3. Speed profile algorithms<br />
<div class="outline-text-5" id="text-1-4-1-2">
<p>
<i>Definition 3.1</i>: A polling policy is regular if arrival does not change the
order of service of the current vehicles.
</p>

<p>
<i>Assumptions</i>: regular policy and sufficiently large control region.
</p>

<p>
MotionSynthesize: minimize area under time-distance graph, such that distance
between vehicles and intersection is minimized at all times. In other words,
the physical queue length is minimized. The original authors solve this
minimization problem by discretizing time and formulating a linear program.
The current paper proposes a similar problem, but instead minimizing the
total amount of absolute acceleration (i.e., area under &rsquo;absolute
acceleration&rsquo;-time graph).
</p>

<p>
Furthermore, they provide <i>closed-form solutions</i> for the above two problems.
</p>

<p>
<span class="underline">Note</span>: Note the tradeoff between minimizing queue length and minimizing energy
consumption. We wonder whether it is possible to switch between these
objectives in a continuous fashion.
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org3f9a87c" class="outline-4">
<h4 id="org3f9a87c"><span class="section-number-4">1.4.2.</span> Oblakova</h4>
<div class="outline-text-4" id="text-1-4-2">
</div>
<ol class="org-ol">
<li><a id="org04a178f"></a>Chapter 4 for MAP construction<br /></li>
</ol>
</div>
<div id="outline-container-orgef835e8" class="outline-4">
<h4 id="orgef835e8"><span class="section-number-4">1.4.3.</span> Noaeen survey</h4>
<div class="outline-text-4" id="text-1-4-3">
<p>
(??, a)
</p>
</div>
<ol class="org-ol">
<li><a id="org1a4ca2d"></a>5.1 common future works and research opportunities<br />
<div class="outline-text-5" id="text-1-4-3-1">
<ul class="org-ul">
<li>test in real wordl</li>
<li>larger networks</li>
<li>generalize traffic lights (more phases, lanes)</li>
<li>different modes of transport</li>
<li>communication delays, unreliability</li>
<li>online learning</li>
</ul>
</div>
</li>
<li><a id="orga1eea47"></a>5.2 key findings<br />
<ol class="org-ol">
<li><a id="org8f05f8c"></a>using different rl methods for different research topics in NTSC<br /></li>
<li><a id="org32654dc"></a>using various state, action, and reward elements in rl methods<br /></li>
<li><a id="org446a928"></a>using and extending the idea of independent rl<br /></li>
<li><a id="org2547be9"></a>using deep rl and hierarchical rl methods in large-scale networks<br /></li>
<li><a id="org0acecab"></a>using deep rl for arterial networks<br /></li>
<li><a id="org6a15b01"></a>automatically achieving coordination along arterial without any prior knowledge using rl<br /></li>
<li><a id="org9c3e16c"></a>using different function approximation (e.g. GAN) in rl methods<br /></li>
<li><a id="org6bf58bf"></a>establishing an appropirate tradeoff between optimality and scalability<br /></li>
<li><a id="orgfa2a869"></a>defining manageable state-space, action-space, and reard function<br /></li>
<li><a id="org9115ad9"></a>reducing the problem space<br /></li>
<li><a id="org8c7213e"></a>defining multiple reward functions for differen traffic situations<br /></li>
<li><a id="org76e44cc"></a>using real traffic data, relaistic networks, and large-scale networks, and considering traffic heterogeneity<br /></li>
<li><a id="org26b3fea"></a>using rl and sensorgrid<br /></li>
<li><a id="orgdbb35e0"></a>integratin the concepts, methods, and frameworks from other fields with rl, such as jta( for coordinated tsc problems ), pro-cep (for predicting future system states), cpt (as a human-centered rl), immune network (for disturbance management)<br /></li>
<li><a id="orgdcb1209"></a>proposing or extending theorectical rl methods/models with feasibility assessment in ntsc<br /></li>
<li><a id="org1b03ff1"></a>using rl in combination with traffic theories<br /></li>
<li><a id="org27af1e3"></a>using rl as a core or combined method in integration with other methods<br /></li>
<li><a id="orgec9b79d"></a>using rl in the integrated traffic systems/networks, including ramp metering, variable message signs, networks of signalized intersections, arterials, and freeways<br /></li>
<li><a id="orgdbf7c57"></a>using statistical relational techniques, such as imitation learning<br /></li>
<li><a id="org8550ce0"></a>using transfer learning in rl<br /></li>
<li><a id="orgd84faa4"></a>using rl in signalized roundabouts, specifically in congested networks<br /></li>
<li><a id="orgda4589e"></a>using rl in perimeter or cordon control<br /></li>
<li><a id="orga026e5a"></a>focusing on explainability when using rl<br /></li>
<li><a id="org90ed28b"></a>cloud/edge/fog-based rl<br /></li>
<li><a id="orgdbc879a"></a>using rl for public transit, whether with or without public transit priority<br /></li>
<li><a id="orga7bf458"></a>usign rl for emergency vehicles<br /></li>
<li><a id="org0892628"></a>using rl in image-based ntsc methods<br /></li>
<li><a id="orgf503a65"></a>using rl in automating streetcar bunching control in transit routes<br /></li>
<li><a id="org9514554"></a>considering the use of rl in mixed environments, including regular, connected and autonomous vehicles<br /></li>
<li><a id="orge660ad7"></a>establishing standard benchmarks for traffic control in traffic simulators<br /></li>
<li><a id="org74e5880"></a>employing online learning<br /></li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-org723d5f4" class="outline-4">
<h4 id="org723d5f4"><span class="section-number-4">1.4.4.</span> Hua Wei</h4>
<div class="outline-text-4" id="text-1-4-4">
<p>
<a href="https://traffic-signal-control.github.io">traffic-signal-control.github.io</a>
</p>
</div>
<ol class="org-ol">
<li><a id="org9f24175"></a>IntelliLight<br /></li>
<li><a id="orgad6ff74"></a>CoLight: GAN for tsc<br /></li>
<li><a id="org882836d"></a>PressLight<br /></li>
<li><a id="org4f21caa"></a>CityFlow (promises to be faster than SUMO)<br />
<div class="outline-text-5" id="text-1-4-4-4">
<p>
It seems that the <a href="https://cityflow.readthedocs.io/en/latest/flow.html">Flow File</a> defines the demand in terms of vehicles that follow a deterministic route, with a fixed time interval in between arrivals.
</p>

<p>
Platoons are not created by default, but the simplicity of the package seems attractive.
</p>
</div>
<ol class="org-ol">
<li><a id="orgc1b701f"></a><a href="https://arxiv.org/abs/1905.05217">paper</a><br /></li>
<li><a id="orga1ceb60"></a><a href="https://cityflow.readthedocs.io/en/latest/">docs</a><br /></li>
<li><a id="org51f3ae9"></a><a href="https://github.com/cityflow-project/CityFlow">github</a><br /></li>
</ol>
</li>
</ol>
</div>
</div>
<div id="outline-container-org6e570de" class="outline-3">
<h3 id="org6e570de"><span class="section-number-3">1.5.</span> context</h3>
<div class="outline-text-3" id="text-1-5">
</div>
<div id="outline-container-org4c4e4f3" class="outline-4">
<h4 id="org4c4e4f3"><span class="section-number-4">1.5.1.</span> topics</h4>
<div class="outline-text-4" id="text-1-5-1">
</div>
<ol class="org-ol">
<li><a id="org1f3b80c"></a>reinforcement learning<br />
<ol class="org-ol">
<li><a id="org32df989"></a>theory and methods<br />
<ol class="org-ol">
<li><a id="org39a6373"></a>model-free<br /></li>
<li><a id="org8167879"></a>value-based learning<br /></li>
</ol>
</li>
<li><a id="org279a8da"></a>bayesian concepts<br />
<ol class="org-ol">
<li><a id="orgf9ccd80"></a>prior knowledge<br /></li>
<li><a id="orgd6aa1b7"></a>prior structure in learning<br /></li>
</ol>
</li>
<li><a id="orge81c018"></a>learning policies from behavior<br />
<ol class="org-ol">
<li><a id="org8a2f08d"></a>generating useful behavior<br /></li>
<li><a id="orgd503333"></a>exploration vs eploitation<br /></li>
<li><a id="orgcd31ae5"></a>offline reinforcement learning<br /></li>
</ol>
</li>
</ol>
</li>
<li><a id="org29b88ef"></a>neural networks<br />
<ol class="org-ol">
<li><a id="org64ad43e"></a>graph neural network<br /></li>
<li><a id="org8eac453"></a>graph attentional network<br /></li>
<li><a id="org6711a62"></a>message passing for graph networks<br /></li>
<li><a id="org29781ed"></a>exploring architectures<br /></li>
</ol>
</li>
<li><a id="org6a364fb"></a>metaheuristics<br /></li>
<li><a id="orgb9fb96d"></a>case study<br />
<ol class="org-ol">
<li><a id="org1ae98ca"></a>traffic<br />
<ol class="org-ol">
<li><a id="orgb8a8983"></a>SUMO<br /></li>
<li><a id="org46b1343"></a>Vissim<br /></li>
<li><a id="org6e69de7"></a>simple discrete simulation<br /></li>
</ol>
</li>
<li><a id="orgf6a2ac1"></a>elementary statistics<br /></li>
</ol>
</li>
<li><a id="org10d9fb8"></a>engineering and scaling<br />
<ol class="org-ol">
<li><a id="orgdbfc5a3"></a>hardware<br />
<div class="outline-text-6" id="text-1-5-1-5-1">
<p>
Invest in a powerful computer with a decent graphics card.
</p>
</div>
</li>
<li><a id="orgd1817c0"></a>cloud computing<br />
<div class="outline-text-6" id="text-1-5-1-5-2">
<p>
Investigate possible cloud computing providers like Azure or AWS.
</p>
</div>
</li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-orga3cf5e3" class="outline-4">
<h4 id="orga3cf5e3"><span class="section-number-4">1.5.2.</span> links</h4>
<div class="outline-text-4" id="text-1-5-2">
</div>
<ol class="org-ol">
<li><a id="orgbe6b5b3"></a><a href="https://www.tue.nl/en/research/research-groups/industrial-engineering/information-systems-ieis/research-areas/ai-for-decision-making">ai for decision making</a><br />
<div class="outline-text-5" id="text-1-5-2-1">
<p>
TU/e group in Industrial Engineering Department that I apparently never heard of before.
</p>
</div>
<ol class="org-ol">
<li><a id="orgc4ab193"></a><a href="https://escf.nl/ai-planner-of-the-future/">AI Planner of the Future</a><br /></li>
<li><a id="org8eb5901"></a><a href="https://www.tue.nl/en/research/researchers/hendrik-baier">Hendrik Baier</a><br />
<ol class="org-ol">
<li><a id="org811501a"></a><a href="https://arxiv.org/abs/2201.11404">Online Planning in POMDPs with Self-Improving Simulators</a><br />
<div class="outline-text-7" id="text-1-5-2-1-2-1">
<p>
N.B.: Frans Oliehoek is also author of the &ldquo;POMDP book&rdquo;
</p>
</div>
</li>
</ol>
</li>
<li><a id="org6f6adbe"></a><a href="https://tspcompetition.com">https://tspcompetition.com</a><br /></li>
</ol>
</li>
<li><a id="org4aacc0a"></a>persons<br />
<ol class="org-ol">
<li><a id="org33e2e3b"></a><a href="https://www.tue.nl/en/research/researchers/hendrik-baier">Hendrik Baier</a><br />
<ol class="org-ol">
<li><a id="org30a320f"></a><a href="https://arxiv.org/abs/2201.11404">Online Planning in POMDPs with Self-Improving Simulators</a><br />
<div class="outline-text-7" id="text-1-5-2-2-1-1">
<p>
N.B.: Frans Oliehoek is also author of the &ldquo;POMDP book&rdquo;
</p>
</div>
</li>
<li><a id="org4bfa911"></a><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baier,+H">arxiv</a><br /></li>
</ol>
</li>
<li><a id="orge633a07"></a>Frans Oliehoek<br />
<ol class="org-ol">
<li><a id="orge1ad65e"></a><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Oliehoek,+F+A">arxiv</a><br /></li>
</ol>
</li>
</ol>
</li>
<li><a id="orgd9eb26f"></a><a href="https://darl-libsignal.github.io">LibSignal</a><br /></li>
<li><a id="org721129e"></a><a href="https://github.com/flow-project/flow">Flow</a><br /></li>
<li><a id="org94c8b35"></a><a href="https://sites.google.com/a/rl-community.org/rl-glue/Home?authuser=0">RL-Glue</a><br /></li>
<li><a id="org9740847"></a>Bram Grooten thesis<br />
<div class="outline-text-5" id="text-1-5-2-6">
<ul class="org-ul">
<li><a href="https://gitlab.tue.nl/jim-portegies/student-projects/bram-grooten">code</a></li>
<li><a href="https://github.com/bramgrooten/DeepRL-for-Hanabi/blob/6d809f65cdae6c7fda360192cce718d8dbe92f78/Hanabi_paper_with_appendix.pdf">paper</a></li>
<li>supervisors: Jim Portegies, Maurice Poot, Jelle Wemmenhove</li>
<li>Thanks &ldquo;High Performance Cluster&rdquo; for their support. From <a href="https://www.cursor.tue.nl/en/news/2022/juli/week-1/hpc-lab-helps-with-computing-problems/">article</a>, it seems
that TU/e didn&rsquo;t acquire a supercomputer, but has a dedicated support team.</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org9b681c6"></a>questions<br />
<ol class="org-ol">
<li><a id="org0a73166"></a>why not value-based learning<br />
<div class="outline-text-7" id="text-1-5-2-6-1-1">
<p>
Or was the choice for policy-based learning mainly motivated by interest?
</p>
</div>
</li>
</ol>
</li>
</ol>
</li>
<li><a id="org900ae80"></a>optimization<br />
<ol class="org-ol">
<li><a id="orge3b4fa2"></a>classification scheme at <a href="https://optimization-online.org/categories/">https://optimization-online.org/categories/</a><br /></li>
</ol>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org46de410" class="outline-2">
<h2 id="org46de410"><span class="section-number-2">2.</span> questions</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-org446abfe" class="outline-3">
<h3 id="org446abfe"><span class="section-number-3">2.1.</span> cutting planes</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Can we define cutting planes based on the observation that choosing some
disjunctive arcs implies that other arcs must also be chosen. Is this what the
non-compact formulation of Lamorgese and Mannino is based on? The reason why I
think this might be the case is that I recognized &ldquo;knapsack&rdquo;-like constraints on
sets in the hotspot paper, where they apply the general path&amp;cycle framework to
this particular problem.
</p>
</div>
</div>
</div>
<div id="outline-container-org4198e1a" class="outline-2">
<h2 id="org4198e1a"><span class="section-number-2">3.</span> work</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org117f4d2" class="outline-3">
<h3 id="org117f4d2"><span class="section-number-3">3.1.</span> mip formulation</h3>
<div class="outline-text-3" id="text-3-1">
</div>
<div id="outline-container-org50727f9" class="outline-4">
<h4 id="org50727f9"><span class="section-number-4">3.1.1.</span> scaling up</h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
We would like to investigate the running time of solving the MIP as a function of
</p>

<ul class="org-ul">
<li>vehicles
<ul class="org-ul">
<li>total rate</li>
<li>patterns (platoons): size and frequency</li>
</ul></li>

<li>network
<ul class="org-ul">
<li>number of intersections</li>
<li>structural complexity
<ul class="org-ul">
<li>tandem</li>
<li>grid</li>
<li>random graph&#x2026;</li>
</ul></li>
</ul></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgd98b51d"></a>instance generator<br />
<div class="outline-text-5" id="text-3-1-1-1">
<p>
for every entrypoint: generate route
</p>

<p>
for every route: generate vehicles
decide release date pattern (with platoons) and total number of vehicles
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org6643119" class="outline-4">
<h4 id="org6643119"><span class="section-number-4">3.1.2.</span> unit testing</h4>
<div class="outline-text-4" id="text-3-1-2">
<p>
automated unit testing on some basic instances
</p>
</div>
</div>
<div id="outline-container-org7040285" class="outline-4">
<h4 id="org7040285"><span class="section-number-4">3.1.3.</span> entrypoints processing time</h4>
<div class="outline-text-4" id="text-3-1-3">
<p>
Entrypoints have no processing time, but these jobs need to travel along the
edge. However, the current schedule visualization draws these operations like
they are jobs, so it looks like the operations is processing, but no travel time
is necessary. Make this clearer.
</p>
</div>
</div>
</div>
<div id="outline-container-org22dd891" class="outline-3">
<h3 id="org22dd891"><span class="section-number-3">3.2.</span> rl formulation</h3>
<div class="outline-text-3" id="text-3-2">
</div>
<div id="outline-container-orgfb3523a" class="outline-4">
<h4 id="orgfb3523a"><span class="section-number-4">3.2.1.</span> rl formulation</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
Two possible flavors come to mind for letting rl schedule vehicles directly. The
first one is based on controlling each intersection separately by setting the
phase of the current time step. This approach is often seen in studies that use
RL with a microsimulator. Secondly, we may consider sequentially scheduling
vehicles on intersections by fixing the crossing times \(y_{ij}\). This approach
would be similar to how the job shop problem is attacked in the paper with
time-step based scheduling. Actions correspond to doing nothing or fixing the
value of one of these variables.
</p>

<p>
Instead of directly learning how to schedule, we could also employ rl in order
to guide the (heuristic) optimization process. For example, in the well-known
<i>shifting bottleneck heuristic</i>, it is necessary to decide in each iteration which
machine to reschedule. It would be interesting to study whether using rl to take
these sequential decisions is feasible. This would provide a more principled
approach than determining the <i>machine criticality</i> based on some index functions
(as seen in Pinedo 7.3, page 204).
</p>
</div>
<ol class="org-ol">
<li><a id="org067a3db"></a>intersection actions<br />
<div class="outline-text-5" id="text-3-2-1-1">
<p>
set <i>phase</i> of intersection
(for each time step)
</p>

<p>
the approach most often seen in studies with SUMO
</p>
</div>
</li>
<li><a id="orgf27f0c7"></a>scheduling actions<br />
<div class="outline-text-5" id="text-3-2-1-2">
<p>
assign vehicle to free intersection time slot
(each time step, either assign or noop)
</p>

<p>
in my opinion, the most obvious for scheduling problems as a better alternative to rolling-horizon approaches with mathematical programming
</p>
</div>
</li>
<li><a id="orgdf20918"></a>guide the optimization process<br />
<div class="outline-text-5" id="text-3-2-1-3">
<p>
decide which machine to reschedule in the shifting bottleneck heuristic for job shop
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org9336096" class="outline-4">
<h4 id="org9336096"><span class="section-number-4">3.2.2.</span> marl</h4>
<div class="outline-text-4" id="text-3-2-2">
</div>
<ol class="org-ol">
<li><a id="orgf122ed9"></a>multi-agent RL has some nice ideas<br />
<ol class="org-ol">
<li><a id="org030bbde"></a>macro-actions<br /></li>
<li><a id="orgb7353e6"></a>max-sum algorithm for negotiating actions across agents<br />
<div class="outline-text-6" id="text-3-2-2-1-2">
<p>
We also are interested in some kind of negotiation scheme among intersections,
since the time slot assignment at an intersection determines the input for other
intersections.
</p>
</div>
</li>
</ol>
</li>
</ol>
</div>
</div>
<div id="outline-container-orge1d6660" class="outline-3">
<h3 id="orge1d6660"><span class="section-number-3">3.3.</span> network editor</h3>
<div class="outline-text-3" id="text-3-3">
</div>
<div id="outline-container-org079e004" class="outline-4">
<h4 id="org079e004"><span class="section-number-4">3.3.1.</span> <a href="https://visjs.github.io/vis-network/docs/network/">vis-network</a></h4>
</div>
<div id="outline-container-orgc83caed" class="outline-4">
<h4 id="orgc83caed"><span class="section-number-4">3.3.2.</span> <a href="https://visjs.github.io/vis-data/data/dataset.html">DataSet</a></h4>
</div>
<div id="outline-container-org4358fb1" class="outline-4">
<h4 id="org4358fb1"><span class="section-number-4">3.3.3.</span> <a href="https://github.com/crubier/react-graph-vis">react-graph-vis wrapper</a></h4>
</div>
<div id="outline-container-orgcc08653" class="outline-4">
<h4 id="orgcc08653"><span class="section-number-4">3.3.4.</span> <a href="https://github.com/visjs/vis-network-react/tree/master">vis-network-react</a></h4>
<div class="outline-text-4" id="text-3-3-4">
<p>
We need to apply useRef and useEffect from React to allow this custom DOM manipulation.
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Jeroen van Riel</p>
<p class="date">Created: 2023-10-18 wo 17:37</p>
</div>
</body>
</html>